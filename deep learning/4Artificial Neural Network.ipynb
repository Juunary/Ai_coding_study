{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(2, 1, bias=True)\n",
    "sigmoid = nn.Sigmoid()\n",
    "model = nn.Sequential(linear, sigmoid).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(10001): \n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0: # 100번째 에포크마다 비용 출력\n",
    "        print(step, cost.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층 퍼셉트콘 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 1, bias=True), # hidden_layer2 = 10, output_layer = 1\n",
    "          nn.Sigmoid()\n",
    "          ).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    # forward 연산\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100의 배수에 해당되는 에포크마다 비용을 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, cost.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손글씨 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # 시각화를 위한 맷플롯립\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits() # 1,979개의 이미지 데이터 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "0\n",
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "#숫자로 이미지 출력\n",
    "print(digits.images[0])\n",
    "#해당 이미지 숫자 의미 출력\n",
    "print(digits.target[0])\n",
    "#images 배열화\n",
    "print(digits.data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = digits.data # 이미지. 즉, 특성 행렬 : [8x8] 행렬\n",
    "Y = digits.target # 각 이미지에 대한 레이블 :0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의: 순차적인 레이어 구조\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(64, 32), # 입력층: 64, 첫 번째 은닉층: 32\n",
    "    nn.ReLU(),         # 활성화 함수: ReLU\n",
    "    nn.Linear(32, 16), # 첫 번째 은닉층: 32, 두 번째 은닉층: 16\n",
    "    nn.ReLU(),         # 활성화 함수: ReLU\n",
    "    nn.Linear(16, 10)  # 두 번째 은닉층: 16, 출력층: 10 (클래스의 개수)\n",
    ")\n",
    "#64>32>16>10 레이어 점점 줄어듬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터 X와 레이블 Y를 텐서로 변환\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrossEntropyLoss는 내부적으로 softmax 함수를 포함하고 있습니다.\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "#Adam은 학습률을 내부적으로 적응적으로 조정하는 방식으로 최적화를 수행합니다.\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "#에포크의 손실(loss) 값을 저장하기 위한 빈 리스트\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100 Cost: 2.306390\n",
      "Epoch   10/100 Cost: 1.982296\n",
      "Epoch   20/100 Cost: 1.649993\n",
      "Epoch   30/100 Cost: 1.267837\n",
      "Epoch   40/100 Cost: 0.936797\n",
      "Epoch   50/100 Cost: 0.681193\n",
      "Epoch   60/100 Cost: 0.498909\n",
      "Epoch   70/100 Cost: 0.376802\n",
      "Epoch   80/100 Cost: 0.294665\n",
      "Epoch   90/100 Cost: 0.237937\n"
     ]
    }
   ],
   "source": [
    "# 총 100번의 에포크 동안 모델 학습\n",
    "for epoch in range(100):\n",
    "  optimizer.zero_grad()      # 옵티마이저의 기울기 초기화\n",
    "  y_pred = model(X)          # 순전파 연산으로 예측값 계산\n",
    "  loss = loss_fn(y_pred, Y)  # 손실 함수로 비용 계산\n",
    "  loss.backward()            # 역전파 연산으로 기울기 계산\n",
    "  optimizer.step()           # 옵티마이저를 통해 파라미터 업데이트\n",
    "\n",
    "  # 10번째 에포크마다 현재 에포크와 손실 값 출력\n",
    "  if epoch % 10 == 0:\n",
    "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, 100, loss.item()\n",
    "        ))\n",
    "\n",
    "  # 손실 값을 리스트에 추가하여 추적\n",
    "  losses.append(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.306389808654785, 2.2633931636810303, 2.2260022163391113, 2.1925907135009766, 2.1616415977478027, 2.1320552825927734, 2.10262393951416, 2.072939872741699, 2.0430521965026855, 2.012845277786255, 1.9822957515716553, 1.9516453742980957, 1.9209181070327759, 1.890205979347229, 1.8592673540115356, 1.8273476362228394, 1.7943787574768066, 1.7600386142730713, 1.7243984937667847, 1.6875340938568115, 1.6499934196472168, 1.612219214439392, 1.57450270652771, 1.5369030237197876, 1.4991090297698975, 1.4609405994415283, 1.4223712682724, 1.3833601474761963, 1.3443390130996704, 1.3056485652923584, 1.2678370475769043, 1.2310938835144043, 1.1952532529830933, 1.1601539850234985, 1.1257340908050537, 1.092137098312378, 1.0593922138214111, 1.0275335311889648, 0.9965680241584778, 0.966358482837677, 0.9367967247962952, 0.9078910946846008, 0.879783570766449, 0.8525018095970154, 0.8260131478309631, 0.8001464605331421, 0.7749564051628113, 0.7504231929779053, 0.7266042232513428, 0.703482449054718, 0.6811928749084473, 0.6597172021865845, 0.6390119791030884, 0.6190736293792725, 0.5998687148094177, 0.5813658833503723, 0.5635736584663391, 0.5464954972267151, 0.5300400853157043, 0.5141888856887817, 0.49890872836112976, 0.4842492341995239, 0.47017601132392883, 0.45670998096466064, 0.4438519775867462, 0.4315934181213379, 0.4198090732097626, 0.4084430932998657, 0.3974906802177429, 0.3869471848011017, 0.3768017888069153, 0.36704394221305847, 0.3576706647872925, 0.3486526906490326, 0.3399891257286072, 0.33167555928230286, 0.32368016242980957, 0.3160060942173004, 0.3086227476596832, 0.30151569843292236, 0.29466527700424194, 0.2880532145500183, 0.2816695272922516, 0.2755192220211029, 0.2695937752723694, 0.26387321949005127, 0.2583392560482025, 0.25298741459846497, 0.2478066086769104, 0.24279242753982544, 0.23793749511241913, 0.23324860632419586, 0.2287251055240631, 0.22435519099235535, 0.22013305127620697, 0.21604831516742706, 0.21208150684833527, 0.2082275003194809, 0.2044915109872818, 0.20088253915309906]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
